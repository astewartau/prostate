{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uqaste15/miniconda3/envs/prostate/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/uqaste15/miniconda3/envs/prostate/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import fastai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from fastMONAI.vision_all import *\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceCELoss\n",
    "\n",
    "import scipy.ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "from useful_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir = \"bids-new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 sessions found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bids-new/sub-z0034542/ses-20220715',\n",
       " 'bids-new/sub-z0186251/ses-20221107',\n",
       " 'bids-new/sub-z0237546/ses-20230508',\n",
       " 'bids-new/sub-z0445614/ses-20230510',\n",
       " 'bids-new/sub-z0705200/ses-20230104',\n",
       " 'bids-new/sub-z0755228/ses-20211108',\n",
       " 'bids-new/sub-z1167038/ses-20220315',\n",
       " 'bids-new/sub-z1181657/ses-20220315',\n",
       " 'bids-new/sub-z1262112/ses-20220314',\n",
       " 'bids-new/sub-z1472355/ses-20221222',\n",
       " 'bids-new/sub-z1568577/ses-20230510',\n",
       " 'bids-new/sub-z1728751/ses-20220328',\n",
       " 'bids-new/sub-z1778013/ses-20220715',\n",
       " 'bids-new/sub-z1818796/ses-20230313',\n",
       " 'bids-new/sub-z2007565/ses-20220715',\n",
       " 'bids-new/sub-z2904752/ses-20220826',\n",
       " 'bids-new/sub-z3171177/ses-20230313',\n",
       " 'bids-new/sub-z3278008/ses-20211109']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_dirs = []\n",
    "for json_path in sorted(glob.glob(os.path.join(bids_dir, \"sub*\", \"ses*\", \"anat\", \"*echo-01*mag*json\"))):\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        if json_data['ProtocolName'] == \"t2starME_qsm_tra_Iso1.4mm_INPHASE_bipolar_RUN_THIS_ONE\":\n",
    "            session_dirs.append(os.sep.join(os.path.split(json_path)[0].split(os.sep)[:-1]))\n",
    "print(f\"{len(session_dirs)} sessions found\")\n",
    "session_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 CT images found.\n",
      "17 CT segmentations found.\n",
      "17 resliced CT images found.\n",
      "17 resliced CT segmentations found.\n",
      "18 QSM images found.\n",
      "18 magnitude images found.\n",
      "18 T2* maps found.\n",
      "18 SWI images found.\n",
      "18 T1w files found.\n",
      "18 resampled T1w files found.\n",
      "18 GRE segmentations found.\n",
      "18 cleaned GRE segmentations found.\n"
     ]
    }
   ],
   "source": [
    "qsm_files = sorted(sum((glob.glob(os.path.join(session_dir, \"extra_data\", \"*qsm_echo2-and-echo4.*\")) for session_dir in session_dirs), []))\n",
    "seg_clean_files = sorted(sum((glob.glob(os.path.join(session_dir, \"extra_data\", \"sub*ses*segmentation_clean.*\")) for session_dir in session_dirs), []))\n",
    "t1_resampled_files = sorted(sum((glob.glob(os.path.join(session_dir, \"extra_data\", \"*t1_tra*_resampled.nii*\")) for session_dir in session_dirs), []))\n",
    "t2s_files = sorted(sum((glob.glob(os.path.join(session_dir, \"extra_data\", \"*t2starmap.nii*\")) for session_dir in session_dirs), []))\n",
    "swi_files = sorted(sum((glob.glob(os.path.join(session_dir, \"extra_data\", \"*swi.nii*\")) for session_dir in session_dirs), []))\n",
    "mag_files = sorted(sum((glob.glob(os.path.join(session_dir, \"extra_data\", \"magnitude_combined.nii\")) for session_dir in session_dirs), []))\n",
    "t1_files = [t1_file.replace(\"_resampled\", \"\") for t1_file in t1_resampled_files]\n",
    "seg_files = [seg_clean_file.replace(\"_clean\", \"\") for seg_clean_file in seg_clean_files]\n",
    "\n",
    "extra_files = sum((glob.glob(os.path.join(session_dir, \"extra_data\", \"*.nii*\")) for session_dir in session_dirs), [])\n",
    "ct_files = [extra_file for extra_file in extra_files if any(pattern in extra_file for pattern in ['_na_', '_Pelvis_']) and not any(pattern in extra_file for pattern in ['_t1_tra_', 'ATX', 'AXT', 'ROI', 'resliced', 'segmentation'])]\n",
    "\n",
    "ct_seg_files = sum((glob.glob(ct_file.replace(\".nii\", \"_segmentation_clean.nii\")) for ct_file in ct_files), [])\n",
    "ct_resliced_files = sum((glob.glob(ct_file.replace(\".nii\", \"_resliced.nii\")) for ct_file in ct_files), [])\n",
    "ct_resliced_seg_files = sum((glob.glob(ct_file.replace(\".nii\", \"_segmentation_clean.nii\")) for ct_file in ct_resliced_files), [])\n",
    "\n",
    "ct_files = [ct_file for ct_file in ct_files if 'z0237546' not in ct_file]\n",
    "ct_seg_files = [ct_file for ct_file in ct_seg_files if 'z0237546' not in ct_file]\n",
    "ct_resliced_files = [ct_file for ct_file in ct_resliced_files if 'z0237546' not in ct_file]\n",
    "ct_resliced_seg_files = [ct_file for ct_file in ct_resliced_seg_files if 'z0237546' not in ct_file]\n",
    "\n",
    "print(f\"{len(ct_files)} CT images found.\")\n",
    "print(f\"{len(ct_seg_files)} CT segmentations found.\")\n",
    "print(f\"{len(ct_resliced_files)} resliced CT images found.\")\n",
    "print(f\"{len(ct_resliced_seg_files)} resliced CT segmentations found.\")\n",
    "print(f\"{len(qsm_files)} QSM images found.\")\n",
    "print(f\"{len(mag_files)} magnitude images found.\")\n",
    "print(f\"{len(t2s_files)} T2* maps found.\")\n",
    "print(f\"{len(swi_files)} SWI images found.\")\n",
    "print(f\"{len(t1_files)} T1w files found.\")\n",
    "print(f\"{len(t1_resampled_files)} resampled T1w files found.\")\n",
    "print(f\"{len(seg_files)} GRE segmentations found.\")\n",
    "print(f\"{len(seg_clean_files)} cleaned GRE segmentations found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(qsm_files) == len(seg_clean_files))\n",
    "assert(len(qsm_files) == len(t2s_files))\n",
    "assert(len(qsm_files) == len(swi_files))\n",
    "assert(len(qsm_files) == len(mag_files))\n",
    "assert(len(qsm_files) == len(t1_resampled_files))\n",
    "assert(len(ct_files) == len(ct_seg_files))\n",
    "assert(len(ct_resliced_files) == len(ct_resliced_seg_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_slices(mask):\n",
    "    labeled_mask = label(mask)\n",
    "    regions = regionprops(labeled_mask)\n",
    "    center_slices = [[round(coord) for coord in region.centroid] for region in regions]\n",
    "    return center_slices\n",
    "\n",
    "class SetVrange(DisplayedTransform):\n",
    "    def __init__(self, vmin, vmax):\n",
    "        self.vmin = vmin\n",
    "        self.vmax = vmax\n",
    "\n",
    "    def encodes(self, o:MedImage):\n",
    "        o[o > self.vmax] = 0\n",
    "        o[o < self.vmin] = 0\n",
    "        return o\n",
    "    \n",
    "def show_images(x, y, figsize=None, fig_out=None):\n",
    "    n_samples = x.shape[0]\n",
    "    n_masks = y.shape[0]\n",
    "    #assert(n_samples == n_masks)\n",
    "    n_samples = max(1, n_masks)\n",
    "\n",
    "    if y.shape[1] > 1:\n",
    "        mask = torch.argmax(y, dim=1).unsqueeze(1).cpu().numpy()\n",
    "    else:\n",
    "        mask = y.cpu().numpy()\n",
    "    mask = np.array(np.round(mask), dtype=int)\n",
    "    data = x.cpu().numpy()\n",
    "\n",
    "    max_sources = 1\n",
    "    for i in range(n_samples):\n",
    "        center_slices = get_center_slices(np.array(mask[i][0] == 1, dtype=int))\n",
    "        n_sources = len(center_slices)\n",
    "        max_sources = max(n_sources, max_sources)\n",
    "    max_sources = min(7, max_sources)\n",
    "\n",
    "    img_width = 2\n",
    "    img_height = 2\n",
    "    wspace = 0.05\n",
    "    hspace = 0.05\n",
    "    n_cols = max_sources\n",
    "    n_rows = n_samples\n",
    "    fig_width = img_width * n_cols + wspace * (n_cols - 1)\n",
    "    fig_height = img_height * n_rows + hspace * (n_rows - 1)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(fig_width, fig_height), squeeze=False)\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_axis_off()\n",
    "    \n",
    "    for i in range(n_rows):\n",
    "        center_slices = get_center_slices(np.array(mask[i][0] == 1, dtype=int))\n",
    "        n_sources = len(center_slices)\n",
    "\n",
    "        for j in range(min(n_sources, n_cols)):\n",
    "            axes[i,j].imshow(data[i][0][:,center_slices[j][1],:], cmap='gray', interpolation='nearest') \n",
    "            axes[i,j].imshow(mask[i][0][:,center_slices[j][1],:], cmap='Set1', vmin=1, vmax=9, alpha=np.array(mask[i][0][:,center_slices[j][1],:] != 0, dtype=int) * 0.6, interpolation='nearest')\n",
    "    plt.tight_layout()\n",
    "    if fig_out: plt.savefig(fig_out)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "@typedispatch\n",
    "def show_batch(x:MedImage, y:MedMask, samples, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n",
    "    show_images(x, y)\n",
    "\n",
    "@typedispatch\n",
    "def show_results(x:MedImage, y:MedMask, samples, outs, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, fig_out='out.png', **kwargs):\n",
    "    outs = torch.stack([outs[i][0] for i in range(len(outs))], dim=0)\n",
    "    show_images(x, y, fig_out=f\"{fig_out.split('.')[0]}_targ.png\")\n",
    "    show_images(x, outs, fig_out=f\"{fig_out.split('.')[0]}_pred.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkersIdentified(fastai.metrics.Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.targ_marker_count = 0\n",
    "        self.pred_marker_count = 0\n",
    "        self.overlap_count = 0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.targ_marker_count = 0\n",
    "        self.pred_marker_count = 0\n",
    "        self.overlap_count = 0\n",
    "    \n",
    "    def accumulate(self, learn=None, pred=None, targ=None):\n",
    "        if pred is None or targ is None:\n",
    "            pred = learn.pred.argmax(dim=1).cpu().numpy()\n",
    "            targ = learn.y.cpu().numpy()\n",
    "        \n",
    "        pred = np.array(np.round(pred) == 1, dtype=int)\n",
    "        targ = np.array(np.round(targ) == 1, dtype=int)\n",
    "\n",
    "        pred = scipy.ndimage.binary_dilation(pred)\n",
    "        targ = scipy.ndimage.binary_dilation(targ)\n",
    "\n",
    "        for i in range(targ.shape[0]):\n",
    "            _, pred_nlabels = scipy.ndimage.label(pred[i])\n",
    "            _, targ_nlabels = scipy.ndimage.label(targ[i])\n",
    "            \n",
    "            overlap = np.array(np.logical_and(pred[i] == targ[i], pred[i] == 1), dtype=int)\n",
    "            _, n_overlaps = scipy.ndimage.label(overlap)\n",
    "            \n",
    "            self.pred_marker_count += pred_nlabels\n",
    "            self.targ_marker_count += targ_nlabels\n",
    "            self.overlap_count += n_overlaps\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return float(self.overlap_count) / max(1., float(self.targ_marker_count))\n",
    "\n",
    "class SuperfluousMarkers(fastai.metrics.Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.targ_marker_count = 0\n",
    "        self.pred_marker_count = 0\n",
    "        self.overlap_count = 0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.targ_marker_count = 0\n",
    "        self.pred_marker_count = 0\n",
    "        self.overlap_count = 0\n",
    "    \n",
    "    def accumulate(self, learn=None, pred=None, targ=None):\n",
    "        if pred is None or targ is None:\n",
    "            pred = learn.pred.argmax(dim=1).cpu().numpy()\n",
    "            targ = learn.y.cpu().numpy()\n",
    "        \n",
    "        pred = np.array(np.round(pred), dtype=int)\n",
    "        targ = np.array(np.round(targ), dtype=int)\n",
    "\n",
    "        pred = scipy.ndimage.binary_dilation(pred)\n",
    "        targ = scipy.ndimage.binary_dilation(targ)\n",
    "\n",
    "        for i in range(targ.shape[0]):\n",
    "            _, pred_nlabels = scipy.ndimage.label(pred[i] == 1)\n",
    "            _, targ_nlabels = scipy.ndimage.label(targ[i] == 1)\n",
    "            overlap = np.array(np.logical_and(pred[i] == targ[i], pred[i] == 1), dtype=int)\n",
    "            _, n_overlaps = scipy.ndimage.label(overlap)\n",
    "            \n",
    "            self.pred_marker_count += pred_nlabels\n",
    "            self.targ_marker_count += targ_nlabels\n",
    "            self.overlap_count += n_overlaps\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return float(self.pred_marker_count - self.overlap_count) / max(1., float(self.pred_marker_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'CT' : [\"CT-Resliced-20230526-114140-best\", [ct_resliced_files], ct_resliced_seg_files, '#a6cee3'],\n",
    "    'QSM+T1' : [\"QSM-T1-NOWEIGHT-20230526-152731-best\", [qsm_files, t1_resampled_files], seg_clean_files, '#1f78b4'],\n",
    "    'QSM' : [\"QSM-NOWEIGHT-20230526-145608-best\", [qsm_files], seg_clean_files, '#b2df8a'],\n",
    "    'T1' : [\"T1-Resampled-20230526-120944-best\", [t1_resampled_files], seg_clean_files, '#33a02c'],\n",
    "    'SWI' : [\"SWI-20230529-152018-best\", [swi_files], seg_clean_files, '#e31a1c'],\n",
    "    'GRE' : [\"GRE-Magnitude-20230526-130737-best\", [mag_files], seg_clean_files, '#fb9a99'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "test_size = 3\n",
    "training_epochs = 700\n",
    "lr = 0.003\n",
    "crop_size = [80, 80, 80] # 128, 160, 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CT ===\n",
      "Splitting...\n",
      "Getting resampling suggestions...\n",
      "Suggested voxel size: [1.4, 1.4, 1.4]\n",
      "Requires resampling: False\n",
      "Largest image size: [146.0, 160.0, 72.0]\n",
      "Creating datablock...\n",
      "Creating dataloaders...\n",
      "Creating learner...\n",
      "Loading model...\n",
      "Transferring to CUDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uqaste15/miniconda3/envs/prostate/lib/python3.8/site-packages/fastai/learner.py:58: UserWarning: Saved filed doesn't contain an optimizer state.\n",
      "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m learn \u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39mload(models[model][\u001b[39m0\u001b[39m])\n\u001b[1;32m     68\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTransferring to CUDA...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m learn\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     71\u001b[0m \u001b[39m# Compute metrics on the entire training dataset\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mComputing metrics...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/prostate/lib/python3.8/site-packages/torch/nn/modules/module.py:749\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    733\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/miniconda3/envs/prostate/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/prostate/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 641 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/prostate/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/prostate/lib/python3.8/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/prostate/lib/python3.8/site-packages/torch/nn/modules/module.py:749\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    733\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/miniconda3/envs/prostate/lib/python3.8/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    230\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "for model in models.keys():\n",
    "    print(f\"=== {model} ===\")\n",
    "    num_data_channels = len(models[model][1])\n",
    "    df = pd.DataFrame({'in_files' : [';'.join(pair) for pair in zip(*models[model][1])], 'seg_files' : models[model][2]})\n",
    "\n",
    "    print(\"Splitting...\")\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    if model == 'CT':\n",
    "        print(\"Getting resampling suggestions...\")\n",
    "        med_dataset = MedDataset(\n",
    "            img_list=train_df.seg_files.tolist(),\n",
    "            dtype=MedMask\n",
    "        )\n",
    "        suggested_voxelsize, requires_resampling = med_dataset.suggestion()\n",
    "        largest_imagesize = med_dataset.get_largest_img_size(resample=suggested_voxelsize)\n",
    "        print(f\"Suggested voxel size: {suggested_voxelsize}\")\n",
    "        print(f\"Requires resampling: {requires_resampling}\")\n",
    "        print(f\"Largest image size: {largest_imagesize}\")\n",
    "    \n",
    "    print(\"Creating datablock...\")\n",
    "    dblock = MedDataBlock(\n",
    "        blocks=(ImageBlock(cls=MedImage), MedMaskBlock),\n",
    "        splitter=RandomSplitter(),#seed=42),\n",
    "        get_x=ColReader('in_files'),\n",
    "        get_y=ColReader('seg_files'),\n",
    "        item_tfms=[\n",
    "            PadOrCrop(crop_size),\n",
    "            RandomFlip(axes=(\"LR\",)),\n",
    "            RandomFlip(axes=(\"AP\",)),\n",
    "            RandomAffine(degrees=(90, 90, 90)),\n",
    "            ZNormalization(),\n",
    "        ],\n",
    "        reorder=requires_resampling,\n",
    "        resample=suggested_voxelsize\n",
    "    )\n",
    "\n",
    "    print(\"Creating dataloaders...\")\n",
    "    dls = DataLoaders.from_dblock(dblock, train_df, bs=4)\n",
    "\n",
    "    print(\"Creating learner...\")\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model=UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=num_data_channels,  # qsm\n",
    "            out_channels=3, # background, marker, calcification\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2\n",
    "        ),\n",
    "        loss_func=DiceCELoss(\n",
    "            to_onehot_y=True,\n",
    "            include_background=True,\n",
    "            softmax=True,\n",
    "            ce_weight=torch.Tensor([1, 1, 1])\n",
    "            #ce_weight=torch.Tensor([0, 0.9998, 0.0002])\n",
    "        ),\n",
    "        opt_func=ranger,\n",
    "        metrics=[multi_dice_score, MarkersIdentified(), SuperfluousMarkers()]#.to_fp16()\n",
    "    )\n",
    "\n",
    "    print(\"Loading model...\")\n",
    "    learn = learn.load(models[model][0])\n",
    "\n",
    "    print(\"Transferring to CUDA...\")\n",
    "    #learn.model.cuda()\n",
    "\n",
    "    # Compute metrics on the entire training dataset\n",
    "    print(\"Computing metrics...\")\n",
    "    correct_markers = MarkersIdentified()\n",
    "    \n",
    "    dblock_train_eval = MedDataBlock(\n",
    "        blocks=(ImageBlock(cls=MedImage), MedMaskBlock),\n",
    "        splitter=IndexSplitter([]),\n",
    "        get_x=ColReader('in_files'),\n",
    "        get_y=ColReader('seg_files'),\n",
    "        item_tfms=[\n",
    "            PadOrCrop(crop_size),\n",
    "            ZNormalization(),\n",
    "        ],\n",
    "        reorder=requires_resampling,\n",
    "        resample=suggested_voxelsize\n",
    "    )\n",
    "    dls_train_eval = DataLoaders.from_dblock(dblock_train_eval, train_df, bs=1, sampler=SequentialSampler)\n",
    "    for x, y in dls_train_eval.train:\n",
    "        pred = torch.argmax(learn.model(x), dim=1).unsqueeze(1).to(dtype=torch.float)\n",
    "        correct_markers.accumulate(pred=pred.cpu(), targ=y.cpu())\n",
    "\n",
    "    print(correct_markers.value)\n",
    "    print(f\"Predicted markers: {correct_markers.pred_marker_count}\")\n",
    "    print(f\"Correct markers: {correct_markers.overlap_count}\")\n",
    "    print(f\"Incorrect markers: {correct_markers.pred_marker_count - correct_markers.overlap_count}\")\n",
    "    print(f\"Target markers: {correct_markers.targ_marker_count}\")\n",
    "\n",
    "    correct_markers.reset()\n",
    "\n",
    "    dblock_test_eval = MedDataBlock(\n",
    "        blocks=(ImageBlock(cls=MedImage), MedMaskBlock),\n",
    "        splitter=IndexSplitter([]),\n",
    "        get_x=ColReader('in_files'),\n",
    "        get_y=ColReader('seg_files'),\n",
    "        item_tfms=[\n",
    "            PadOrCrop(crop_size),\n",
    "            ZNormalization(),\n",
    "        ],\n",
    "        reorder=requires_resampling,\n",
    "        resample=suggested_voxelsize\n",
    "    )\n",
    "\n",
    "    dls_test_eval = DataLoaders.from_dblock(dblock_test_eval, test_df, bs=1, sampler=SequentialSampler)\n",
    "    for x, y in dls_test_eval.train:\n",
    "        pred = torch.argmax(learn.model(x), dim=1).unsqueeze(1).to(dtype=torch.float)\n",
    "        correct_markers.accumulate(pred=pred.cpu(), targ=y.cpu())\n",
    "\n",
    "    print(correct_markers.value)\n",
    "    print(f\"Predicted markers: {correct_markers.pred_marker_count}\")\n",
    "    print(f\"Correct markers: {correct_markers.overlap_count}\")\n",
    "    print(f\"Incorrect markers: {correct_markers.pred_marker_count - correct_markers.overlap_count}\")\n",
    "    print(f\"Target markers: {correct_markers.targ_marker_count}\")\n",
    "\n",
    "    loss, *metrics = learn.validate(ds_idx=0, dl=dls_train_eval.train)\n",
    "    print(\"TRAINING SET METRICS\")\n",
    "    print(f\"Dice score: {metrics[0]}; Markers identified: {metrics[1]}; Superfluous markers: {metrics[2]}\")\n",
    "    #learn.show_results(anatomical_plane=0, dl=dls_train_eval.train, fig_out='seg_results_train.png')\n",
    "\n",
    "    loss, *metrics = learn.validate(ds_idx=0, dl=dls_test_eval.train)\n",
    "    print(\"TEST SET METRICS\")\n",
    "    print(f\"Dice score: {metrics[0]}; Markers identified: {metrics[1]}; Superfluous markers: {metrics[2]}\")\n",
    "    #learn.show_results(anatomical_plane=0, dl=dls_test_eval.train, fig_out='seg_results_test.png')\n",
    "\n",
    "    # get predictions\n",
    "    dls_train_eval = DataLoaders.from_dblock(dblock_train_eval, train_df, bs=len(dls_train_eval.train_ds), sampler=SequentialSampler)\n",
    "    dls_test_eval = DataLoaders.from_dblock(dblock_test_eval, test_df, bs=len(dls_test_eval.train_ds), sampler=SequentialSampler)\n",
    "\n",
    "    train_x, train_y = dls_train_eval.train.one_batch()\n",
    "    test_x, test_y = dls_test_eval.train.one_batch()\n",
    "\n",
    "    def calc_stuff(x, y):\n",
    "        pred = learn.model(x)[:,1,:,:,:].unsqueeze(1).cpu().detach().numpy()\n",
    "        pred -= np.min(pred)\n",
    "        pred /= np.max(pred)\n",
    "        pred = pred.flatten()\n",
    "        targ = (y.cpu() == 1).to(dtype=torch.int).detach().numpy().flatten()\n",
    "\n",
    "        # calculate AUC\n",
    "        sample_weight = compute_sample_weight(class_weight=\"balanced\", y=targ, indices=None)\n",
    "        fpr, tpr, thresholds = roc_curve(targ, pred, sample_weight=sample_weight)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # calculate precision-recall curve\n",
    "        precision, recall, _ = precision_recall_curve(targ, pred)\n",
    "        average_precision = average_precision_score(targ, pred)\n",
    "\n",
    "        return fpr, tpr, precision, recall, thresholds, average_precision, roc_auc\n",
    "    \n",
    "    fpr, tpr, precision, recall, thresholds, average_precision, roc_auc = calc_stuff(train_x, train_y)\n",
    "\n",
    "    # Plotting ROC Curve\n",
    "    #plt.figure()\n",
    "    #plt.plot(fpr, tpr, color=models[model][3], label=f'{model} (AUC = {round(roc_auc, 2)})')\n",
    "\n",
    "    # Plotting Precision-Recall Curve\n",
    "    #plt.figure()\n",
    "    plt.plot(recall, precision, color=models[model][3], label=f'{model}')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve\\n(Training set)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"out.png\", dpi=400)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "#plt.ylim([0.0, 1.05])\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.title('Receiver Operating Characteristic (ROC) Curve\\n(Test set)')\n",
    "#plt.legend(loc=\"lower right\")\n",
    "#plt.savefig(\"out.png\", dpi=400)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prostate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03f67c3c00010b009bb49c0b41212a310c824d817af9d8224888fa5a5f2c519c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
