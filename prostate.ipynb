{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold marker segmentation with QSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from glob import glob\n",
    "import fastai.vision.learner\n",
    "import fastai.vision.models\n",
    "import fastai.data.core\n",
    "import fastai.callback.all\n",
    "import fastai.losses\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import cv2\n",
    "import skimage.measure\n",
    "import scipy.ndimage\n",
    "from useful_functions import *\n",
    "import fastMONAI.vision_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "### Locate input data\n",
    "\n",
    "The files are 3D NIfTI images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "qsm_files = sorted(glob(\"data/bids/sub-*/ses-*/extra_data/*qsm.nii*\"))\n",
    "seg_files = sorted(glob(\"data/bids/sub-*/ses-*/extra_data/*segmentation*clean_seeds.nii*\"))\n",
    "t2s_files = sorted(glob(\"data/bids/sub-*/ses-*/extra_data/*t2starmap.nii*\"))\n",
    "mag_files = sorted(glob(\"data/bids/sub-*/ses-*/extra_data/*magnitude_combined.nii*\"))\n",
    "assert(len(qsm_files) == len(seg_files))\n",
    "print(f\"{len(qsm_files)} NIfTI image sets found in data/bids (QSM, segmentations).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_dataset = fastMONAI.vision_all.MedDataset(img_list=[qsm_files[0]], dtype=fastMONAI.vision_all.MedMask, max_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load samples as a PyTorch dataset and fastai 'dataloaders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QSM_3D_With_Seg(torch.utils.data.Dataset):\n",
    "    def __init__(self, seg_files, qsm_files, transform=None):\n",
    "        self.seg_files = seg_files\n",
    "        self.qsm_files = qsm_files\n",
    "        self.transform = transform\n",
    "        self.vocab = np.array(['Prostate', 'Gold marker'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qsm_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # convert idx to list if tensor\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # convert idx to image and slice numbers\n",
    "        seg_path = self.seg_files[idx]\n",
    "        qsm_path = self.qsm_files[idx]\n",
    "\n",
    "        # load data\n",
    "        qsm = nib.load(qsm_path).get_fdata()\n",
    "        seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "        # scale qsm\n",
    "        qsm = np.interp(np.clip(qsm, -2, +2), (-2, +2), (0, 1))\n",
    "        qsm = (qsm - qsm.mean()) / qsm.std() * 0.229 + 0.485\n",
    "\n",
    "        # select slice\n",
    "        #qsm = qsm[:,:,int(slice_id)]\n",
    "        #seg = seg[:,:,int(slice_id)]\n",
    "\n",
    "        # resize images to common size\n",
    "        #qsm = torch.Tensor(cv2.resize(qsm, dsize=(224, 224, 224)))\n",
    "        #seg = torch.Tensor(cv2.resize(seg, dsize=(224, 224, 224), interpolation=cv2.INTER_NEAREST))\n",
    "\n",
    "        qsm = torch.Tensor(scipy.ndimage.zoom(qsm, (224/qsm.shape[0], 224/qsm.shape[1], 224/qsm.shape[2]), mode='nearest'))\n",
    "        seg = torch.Tensor(scipy.ndimage.zoom(seg, (224/seg.shape[0], 224/seg.shape[1], 224/seg.shape[2]), mode='nearest'))\n",
    "\n",
    "        seg = seg.to(torch.int64)\n",
    "\n",
    "        # expand qsm over 3 dimensions\n",
    "        #qsm = qsm.expand(3, 224, 224)\n",
    "\n",
    "        # rotate image\n",
    "        #num_rotations = idx // len(self.sample_details)\n",
    "        #seg = torch.rot90(seg, num_rotations, [0, 1])\n",
    "        #qsm = torch.rot90(qsm, num_rotations, [1, 2])\n",
    "\n",
    "        return fastai.torch_core.TensorImage(qsm), fastai.torch_core.TensorMask(seg)#, codes=['FM', 'Calcification'])\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx in range(len(self.sample_details)):\n",
    "            yield self.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = QSM_3D_With_Seg(qsm_files=qsm_files[:10], seg_files=seg_files[:10])\n",
    "valid_ds = QSM_3D_With_Seg(qsm_files=qsm_files[10:], seg_files=seg_files[10:])\n",
    "dls = fastai.data.core.DataLoaders.from_dsets(train_ds, valid_ds, batch_size=2, device='cuda:0')\n",
    "print(f\"Training set contains {len(train_ds)} samples.\")\n",
    "print(f\"Validation set contains {len(valid_ds)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dls.train.one_batch() # batch[type][idx][rgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch[0][0].cpu() \n",
    "y = batch[1][0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_histogram(x, title=\"Input - After creating dataset\", mask=y, dim=2, n_ticks=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return ((2. * intersection) / (iflat.sum() + tflat.sum()))\n",
    "\n",
    "def dice_score(input, target):\n",
    "    pred = input.cpu().argmax(1)[0]\n",
    "    num_seeds_target = np.max(np.unique(skimage.measure.label(np.array(target.cpu()[0]))))\n",
    "    num_seeds_pred = np.max(np.unique(skimage.measure.label(np.array(pred))))\n",
    "    print(\"num_seeds_target\", num_seeds_target)\n",
    "    print(\"num_seeds_pred\", num_seeds_pred)\n",
    "    #show_image(label)\n",
    "    #test_ad()\n",
    "    return dice(input.argmax(1), target)\n",
    "\n",
    "def dice_loss(input, target): \n",
    "    return 1 - dice(input.softmax(1)[:, 1], target)\n",
    "\n",
    "def loss(input, target):\n",
    "    return dice_loss(input, target) + nn.CrossEntropyLoss()(input, target[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fastai.vision.learner.unet_learner(\n",
    "    dls=dls,\n",
    "    arch=fastai.vision.models.resnet34,\n",
    "    n_out=2,\n",
    "    loss_func=fastai.losses.CrossEntropyLossFlat(axis=1),\n",
    "    model_dir='models',\n",
    "    normalize=False,\n",
    "    metrics=dice_score#fastai.learner.AvgLoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT RANGE CHANGES AFTER CREATING LEARNER???\n",
    "batch = dls.one_batch() # batch[type][idx][rgb]\n",
    "x = batch[0][0][0].cpu() \n",
    "y = batch[1][0].cpu()\n",
    "\n",
    "show_histogram(x, title=\"Input - After creating learner\", mask=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT RANGE CHANGES AFTER CREATING LEARNER???\n",
    "batch = dls.valid.one_batch() # batch[type][idx][rgb]\n",
    "x = batch[0][0][0].cpu() \n",
    "y = batch[1][0].cpu()\n",
    "\n",
    "show_histogram(x, title=\"Input - After creating learner\", mask=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(3, base_lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dls.train.one_batch() # batch[type][idx][rgb]\n",
    "x = batch[0][0][0].cpu()\n",
    "y = batch[1][0].cpu()\n",
    "\n",
    "show_histogram(x, title=\"Ground truth (from training set)\", mask=y)\n",
    "\n",
    "_, _, prediction = learn.predict(batch[0][0].unsqueeze(0))\n",
    "prediction = torch.round(prediction)\n",
    "\n",
    "show_histogram(x, title=\"Prediction\", mask=prediction[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dls.valid.one_batch() # batch[type][idx][rgb]]\n",
    "x = batch[0][4][0].cpu()\n",
    "y = batch[1][4].cpu()\n",
    "\n",
    "show_histogram(x, title=\"Ground truth (from validation set)\", mask=y)\n",
    "\n",
    "_, _, prediction = learn.predict(batch[0][0].unsqueeze(0))\n",
    "prediction = torch.round(prediction)\n",
    "\n",
    "show_histogram(x, title=\"Prediction\", mask=prediction[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = fastai.interpret.ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('prostate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7019b790fc5606173c861eaa41f45209767a1ab20fcb6229725b6182650c93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
